{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e8960c",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f940d",
   "metadata": {},
   "source": [
    "Neutrino physicists are interested determining the properties of neutrinos that interact within our detector. These include, for example, the energy, direction, and flavor of the neutrino. In IceCube, the most common flavors of neutrinos are electron neutrions ($\\nu_e$) and muon neutrinos ($\\nu_\\mu$). Knowing the flavor of neutrino helps us learn more about how these cosmological neutrinos are produced. We can tell the flavor of the neutrino by the type of particle it produces: electron neutrinos produce electrons, and muon neutrinos produce muons.\n",
    "\n",
    "Below you can see an example of a **track** from a muon (left) and a **cascade** from an electron (right) in IceCube. The spheres show the sensors of the detector that have observed light. Larger spheres mean that more photons were observed, and the color indicates the time that photons hit the sensor, where red is earlier and green is later. We can use the different shapes to tell which type of neutrino hit the detector.\n",
    "\n",
    "![](../resources/images/track_cascade.png)\n",
    "\n",
    "In this activity, we will try to distinguish between electrons and muons in IceCube using artificial intelligence. We will train a neural network similar to the one depicted below using images of tracks and cascades in IceCube. You can tweak the parameters of the network to try to get the best performance possible. Then, you can see how your own guesses for the neutrino flavor compare to those of the network!\n",
    "\n",
    "<img src=\"../resources/images/neural_network.png\" alt=\"nn\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a0a63",
   "metadata": {},
   "source": [
    "First, we will need to download the data from google drive and import some Python code that will help run this exercise. Assuming you are using Google Colab, the files will not download to your own computer. Run the cell below by clicking the button in the top left corner, or by pressing shift+enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf72264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed for figures to appear in colab \n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "!rm -rf sample_data\n",
    "\n",
    "# download reduced_electrons.parquet\n",
    "!gdown https://drive.google.com/uc?id=1BVTkqniSfwJsVsUnNhM_FjMueXfotr2f\n",
    "\n",
    "# download reduced_muons.parquet\n",
    "!gdown https://drive.google.com/uc?id=1nJpyojI8CAwaq5P_ZcqgeKhfBEVCQn9n\n",
    "\n",
    "# download pre-prepared analysis code\n",
    "!rm -rf IceCube_MasterClass_at_Harvard2024\n",
    "!git clone \"https://github.com/kcarloni/IceCube_MasterClass_at_Harvard2024\";\n",
    "\n",
    "# Import some standard python libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import some custom libraries for this example\n",
    "sys.path.insert(0, \"./IceCube_MasterClass_at_Harvard2024/\")\n",
    "from src.ml_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546ac34",
   "metadata": {},
   "source": [
    "The next cell takes the datasets that we just downloadaed and turns them into a format that we can use to train the neural network. Then, we create the network and the training dataest. There are two variables that you can play with here:\n",
    "- \"width\": this determines the width of the hidden layer of the network. A larger width means that the network will have more parameters\n",
    "- \"N_train\": this determines the number of IceCube images to use to train the network. More training data will *generally* lead to better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a Python class that will guide this ML example\n",
    "ML_Helper = MLHelper(\"reduced_muons.parquet\",\n",
    "                     \"reduced_electrons.parquet\")\n",
    "\n",
    "width = 10 # how \"wide\" the network is, which will determine the number of paremeters\n",
    "N_train = 1000 # how many training examples to use. Pick a number between 1 and 4999\n",
    "\n",
    "# Make the network\n",
    "ML_Helper.MakeNetwork(width=width)\n",
    "\n",
    "# Make the training data\n",
    "ML_Helper.MakeTrainingDataset(N_train=N_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b56e95",
   "metadata": {},
   "source": [
    "Now let's train the network! We will pass through the training data a certain number of times and adjust the parameters of the neural network as we go. We are using the binary cross entropy (BCE) loss function, which is the standard choice when trying to classify data into two different categories. There is a single variable you can play with here:\n",
    "- \"num_epochs\": the number of times to pass through the training data. More epochs will *generally* lead to better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d12786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train the network using the binary cross entropy loss function\n",
    "num_epochs = 2 # decide how many times you want to pass through the training data\n",
    "loss_dict = ML_Helper.train(num_epochs=num_epochs)\n",
    "for epoch,losses in loss_dict.items():\n",
    "    if epoch>0:\n",
    "        plt.plot(epoch*len(losses)-1+np.arange(len(losses)+1),np.array([loss_dict[epoch-1][-1]]+losses),label=epoch)\n",
    "    else:\n",
    "        plt.plot(epoch*len(losses)+np.arange(len(losses)),np.array(losses),label=epoch)\n",
    "plt.semilogy()\n",
    "plt.ylabel(\"BCE Loss\",fontsize=14)\n",
    "plt.xlabel(\"Training Step\",fontsize=14)\n",
    "l = plt.legend(fontsize=14)\n",
    "l.set_title(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0febb3",
   "metadata": {},
   "source": [
    "Now that we've trained the network, let's have some fun with it! Here you can look at different IceCube events and try to guess which neutrino flavor you're looking at, $\\nu_e$ or $\\nu_\\mu$. Use the \"event_no\" variable to select which event to show. You can use the \"reveal_network_prediction\" and \"reveal_true_label\" variables between True and False to toggle whether to reveal the network's guess for the event and the true neutrino type of the event. The network prediction will be closer to 0 if the network thinks the event is a muon, and 1 if the network thinks the event is an electron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe133ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_no = 1 # which event to show\n",
    "ML_Helper.plot_event(event_no,\n",
    "                    reveal_network_predition=False, # whether to reveal the network's guess for the event\n",
    "                    reveal_true_label=False # whether to reveal the true neutrino flavor for the event\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003b8ca1",
   "metadata": {},
   "source": [
    "Let's see how well our network does for many events. Here we show the network many IceCube images of electrons and muons that it didn't see during training. You can see how well your network does at predicting the neutrino flavor for these events by seeing whether the muons cluster around 0 and the electrons cluster around 1 in the histogram below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9311d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save network scores on the test data\n",
    "pred_label_test = []\n",
    "true_label_test = []\n",
    "for input,target in ML_Helper.test_dataloader:\n",
    "    output = ML_Helper.net(input).detach().numpy()\n",
    "    true_label_test += list(target[:,0])\n",
    "    pred_label_test += list(output[:])\n",
    "pred_test = np.array(pred_label_test,dtype=float)\n",
    "true_test = np.array(true_label_test,dtype=float)\n",
    "\n",
    "# Plot network score distributions\n",
    "bins = np.linspace(0,1,10)\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.hist(pred_test[true_test==0],alpha=0.5,bins=bins,label=\"Muons\",color=\"dodgerblue\")\n",
    "plt.hist(pred_test[true_test==1],alpha=0.5,bins=bins,label=\"Electrons\",color=\"orangered\")\n",
    "plt.xlabel(\"Electron score\", fontsize=14)\n",
    "plt.ylabel(\"Number of events\",fontsize=14)\n",
    "plt.semilogy()\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
